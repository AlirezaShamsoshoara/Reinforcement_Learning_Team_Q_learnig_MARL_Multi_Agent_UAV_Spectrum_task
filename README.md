# A solution for dynamic spectrum management in mission-critical UAV networks using Team Q learning as a Multi-agent Reinforcement Learning Approach

## Paper
You can find the paper related to this code [here at IEEE](https://ieeexplore.ieee.org/abstract/document/8824917) or
You can find the preprint from the [Arxiv website](https://arxiv.org/pdf/1904.07380.pdf)

In the related, we study the problem of spectrum scarcity in a network of unmanned aerial vehicles (UAVs) during mission-critical applications such as disaster monitoring and public safety missions, where the preallocated spectrum is not sufficient to offer a high data transmission rate for real-time video-streaming. In such scenarios, the UAV network can lease part of the spectrum of a terrestrial licensed network in exchange for providing relaying service. In order to optimize the performance of the UAV network and prolong its lifetime, some of the UAVs will function as a relay for the primary network while the rest of the UAVs carry out their sensing tasks. Here, we propose a team reinforcement learning algorithm performed by the UAVâ€™s controller unit to determine the optimum allocation of sensing and relaying tasks among the UAVs as well as their relocation strategy at each time. We analyze the convergence of our algorithm and present simulation results to evaluate the system throughput in different scenarios.

The system model of this paper is based on:


## Code


## Required Packages

## Results


## Citation
```
@inproceedings{shamsoshoara2019solution,
  title={A solution for dynamic spectrum management in mission-critical UAV networks},
  author={Shamsoshoara, Alireza and Khaledi, Mehrdad and Afghah, Fatemeh and Razi, Abolfazl and Ashdown, Jonathan and Turck, Kurt},
  booktitle={2019 16th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}
```

## License
For academtic and non-commercial usage 
